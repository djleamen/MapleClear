# ğŸ MapleClear

> Simplifying Canadian government webpages into plain language with local AI

MapleClear is a browser extension that uses local AI inference to simplify complex government text and translate it into multiple languages, making Canadian government information more accessible to all citizens.

Submitted to the [OpenAI Open Model Hackathon](https://openai.devpost.com)
Categories: For Humanity (primary), Best Local Agent (secondary), Most Useful Fine-Tune (secondary)

## Features

- **Plain Language Simplification**: Convert complex government jargon into Grade 7 reading level
- **Multi-Language Translation**: Translate to French, Spanish, Chinese, Punjabi, Arabic, and more
- **Split-Screen View**: Compare original and simplified/translated content side-by-side
- **Acronym Detection**: Hover tooltips for government acronyms (CRA, EI, GST, etc.)
- **Local AI Processing**: Privacy-first approach using local inference
- **Government Site Integration**: Optimized for Canada.ca and gc.ca domains

## Architecture

### Browser Extension (`/extension/`)
- **Popup Interface** (`popup.html`, `popup.js`): Main extension UI with action selection
- **Split-Screen Mode** (`content-script.ts`): Side-by-side comparison of original vs processed content
- **Panel View** (`panel.html`, `panel.js`): Advanced processing options and results
- **Background Service** (`background.ts`): Extension lifecycle and server status monitoring
- **Manifest V3** (`manifest.json`): Modern extension configuration

### Local AI Server (`/server/`)
```
server/
â”œâ”€â”€ app.py                 # FastAPI server with health checks and CORS
â”œâ”€â”€ backends/              # Pluggable AI inference backends
â”‚   â”œâ”€â”€ base.py           # Abstract backend interface
â”‚   â”œâ”€â”€ groq_backend.py   # Groq API integration (default)
â”‚   â”œâ”€â”€ huggingface_backend.py  # Local transformers
â”‚   â”œâ”€â”€ lmstudio_backend.py     # LM Studio integration
â”‚   â”œâ”€â”€ vllm_backend.py   # vLLM for production
â”‚   â””â”€â”€ llama_cpp.py      # llama.cpp integration
â””â”€â”€ prompts/
    â””â”€â”€ schema.py         # Response models and validation
```

### Key Components

#### Backend Abstraction
All AI backends implement the same interface:
- `simplify()` - Convert to plain language
- `translate()` - Multi-language translation  
- `expand_acronyms()` - Government acronym definitions
- `get_model_info()` - Backend status and capabilities

#### Model Support
- **Groq API**: Fast cloud inference (default for demos)
- **Local Models**: gpt-oss-20b, Llama 2/3, Mistral
- **Apple Silicon**: Optimized through LM Studio integration
- **Quantization**: 8-bit/16-bit for resource efficiency

## Quick Start

### 1. Install Dependencies

**Server:**
```bash
cd server
pip install -r requirements-minimal.txt
```

**Extension:**
```bash
cd extension
npm install
npm run build
```

### 2. Start the Server

**Using Groq:**
```bash
./setup.sh
make dev-server
```
OR
```bash
export GROQ=your_groq_api_key
python -m uvicorn server.app:app --host 127.0.0.1 --port 11434
```

**Using Local Models:**
```bash
export MAPLECLEAR_BACKEND=huggingface
export MAPLECLEAR_MODEL_PATH=openai/gpt-oss-20b
python -m uvicorn server.app:app --host 127.0.0.1 --port 11434
```

### 3. Load Extension

1. Open Chrome and navigate to `chrome://extensions/`
2. Enable "Developer mode"
3. Click "Load unpacked" and select the `extension/dist` folder
4. Visit a Canada.ca page and click the MapleClear icon

## Development

### Backend Switching
```bash
export MAPLECLEAR_BACKEND=groq        # Groq API (fast)
export MAPLECLEAR_BACKEND=lmstudio    # LM Studio (Apple Silicon optimized)
export MAPLECLEAR_BACKEND=huggingface # Local transformers
export MAPLECLEAR_BACKEND=vllm        # Production inference
```

### Extension Development
```bash
cd extension
npm run dev  # Watch mode for development
npm run build  # Production build
```

### Testing
```bash
# Test server
cd server && python -m pytest

# Test extension
cd extension && npm test

# Demo page
open demo/canada-benefits.html
```

## ğŸ“ Project Structure

```
MapleClear/
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE                       # Apache 2.0 license
â”œâ”€â”€ Makefile                      # Build automation
â”œâ”€â”€ setup.sh                      # Environment setup
â”œâ”€â”€ .env                          # Environment variables
â”œâ”€â”€ .gitignore                    # Git ignore patterns
â”‚
â”œâ”€â”€ server/                       # FastAPI backend
â”‚   â”œâ”€â”€ app.py                    # Main server application
â”‚   â”œâ”€â”€ requirements.txt          # Full dependencies
â”‚   â”œâ”€â”€ requirements-minimal.txt  # Minimal setup
â”‚   â”œâ”€â”€ backends/                 # AI inference backends
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py                 # Abstract backend class
â”‚   â”‚   â”œâ”€â”€ groq_backend.py         # Groq API integration
â”‚   â”‚   â”œâ”€â”€ huggingface_backend.py  # Local transformers
â”‚   â”‚   â”œâ”€â”€ lmstudio_backend.py     # LM Studio integration
â”‚   â”‚   â”œâ”€â”€ vllm_backend.py         # vLLM inference
â”‚   â”‚   â””â”€â”€ llama_cpp.py            # llama.cpp integration
â”‚   â””â”€â”€ prompts/
â”‚       â””â”€â”€ schema.py           # Pydantic models
â”‚
â”œâ”€â”€ extension/                  # Browser extension
â”‚   â”œâ”€â”€ package.json            # Extension dependencies
â”‚   â”œâ”€â”€ vite.config.ts          # Build configuration
â”‚   â”œâ”€â”€ tsconfig.json           # TypeScript configuration
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ manifest.json       # Extension manifest (MV3)
â”‚   â”‚   â”œâ”€â”€ popup.html          # Extension popup UI
â”‚   â”‚   â”œâ”€â”€ popup.js            # Popup functionality
â”‚   â”‚   â”œâ”€â”€ popup.css           # Popup styling
â”‚   â”‚   â”œâ”€â”€ panel.html          # Advanced panel UI
â”‚   â”‚   â”œâ”€â”€ panel.js            # Panel functionality  
â”‚   â”‚   â”œâ”€â”€ panel.css           # Panel styling
â”‚   â”‚   â”œâ”€â”€ content-script.ts   # Page interaction logic
â”‚   â”‚   â”œâ”€â”€ content-styles.css  # Content script styling
â”‚   â”‚   â”œâ”€â”€ background.ts       # Service worker
â”‚   â”‚   â””â”€â”€ browser-polyfill.js # Cross-browser compatibility
â”‚   â””â”€â”€ dist/                   # Built extension files
â”‚
â”œâ”€â”€ tools/
â”‚   â””â”€â”€ seed_terms.py         # Government acronym database
â”‚
â””â”€â”€ demo/
    â””â”€â”€ canada-benefits.html  # Test page with government content
```

## ğŸ”§ Configuration

### Environment Variables
```bash
# Server Configuration
MAPLECLEAR_BACKEND=groq                   # AI backend selection
MAPLECLEAR_MODEL_PATH=openai/gpt-oss-20b  # Model path
MAPLECLEAR_HOST=127.0.0.1                 # Server host
MAPLECLEAR_PORT=11434                     # Server port

# API Keys (if using cloud backends)
GROQ=your_groq_api_key                  # Groq API key

# Database
MAPLECLEAR_TERMS_DB=data/terms.sqlite   # Acronym database
```

### Backend Options

| Backend | Use Case | Requirements |
|---------|----------|-------------|
| `groq` | Fast demos, cloud inference | API key |
| `lmstudio` | Apple Silicon local inference | LM Studio app |
| `huggingface` | Local transformers | GPU/CPU, 8GB+ RAM |
| `vllm` | Production deployment | GPU, high memory |
| `llama.cpp` | CPU inference | Compiled llama.cpp |

## Use Cases

### For Citizens
- Understand tax documents and benefit applications
- Navigate government services in plain language
- Access information in your preferred language
- Learn government acronyms and terminology

### For Government
- Improve accessibility and comprehension
- Reduce support calls and clarification requests
- Meet plain language standards
- Support diverse linguistic communities

## Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/amazing-feature`
3. Commit changes: `git commit -m 'Add amazing feature'`
4. Push to branch: `git push origin feature/amazing-feature`
5. Open a Pull Request

## License

This project is licensed under the Apache License 2.0 - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- OpenAI for the gpt-oss models used in development and hosting the Open Model Hackathon
- Hackathon sponsors HuggingFace, Ollama, vLLM, NVIDIA, LM Studio
- Groq for providing free API credits to hackathon participants (needed for my testing)
- Government of Canada for open data and plain language initiatives
- The open source AI community for tools and inspiration

---

**âš ï¸ Note**: This is experimental software. AI-generated results should be reviewed for accuracy before use in official contexts.
